% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_ingestion.R
\name{parse_to_parquet_parallel}
\alias{parse_to_parquet_parallel}
\title{Parse Files to Parquet in Parallel}
\usage{
parse_to_parquet_parallel(
  file_paths,
  output_dir,
  n_workers = NULL,
  batch_size = 500,
  progress = TRUE
)
}
\arguments{
\item{file_paths}{Character vector of paths to JSON files}

\item{output_dir}{Directory to write Parquet files}

\item{n_workers}{Number of parallel workers}

\item{batch_size}{Files per worker batch}

\item{progress}{Show progress bar}
}
\value{
List with total matches parsed and errors
}
\description{
Parses JSON files in parallel, with each worker writing to Parquet files.
This approach minimizes memory usage by flushing to disk.
}
\keyword{internal}
